# -*- coding: utf-8 -*-
"""
MyCobot 320 M5 + YOLO ê°ì§€ + OpenCV ê¸°ë°˜ ê°ë„ ì¶”ì •
(ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„° ì§ì ‘ ë‚´ì¥ ë²„ì „)
"""

import time, argparse, threading, cv2, math, numpy as np
from ultralytics import YOLO

try:
    from pymycobot.mycobot320 import MyCobot320 as CobotClass
except Exception:
    from pymycobot.mycobot import MyCobot as CobotClass


# ===================== í¬ì¦ˆ ì„¤ì • =====================
POSE_HOME   = [-264.3, 66.4, 325.0, -177.3, 7.78, 1.83]
POSE_CLEAR  = [-254.4, -17.4, 350.6, -178.78, 15.16, 1.6]
POSE_PLACE1 = [-152.4,  181.4, 228.1, -170.3,   6.5,   38.8]   # ì–‘í’ˆ
POSE_PLACE2 = [ -37.3,  318.6, 170.2,  162.81, -2.81, -29.21]  # ë¶ˆëŸ‰í’ˆ
DEFAULT_SPEED = 25

# ===================== ë³´ì • íŒŒë¼ë¯¸í„° =====================
SCALE_X = 0.33
SCALE_Y = 0.35
OFFSET_X = -5.0
OFFSET_Y = -85.0
is_defect = False


# ===================== ì¹´ë©”ë¼ ë‚´ë¶€ ë³´ì • íŒŒë¼ë¯¸í„° (ì§ì ‘ ì‚½ì…) =====================
K = np.array([
    [539.1372906745268, 0.0, 329.02126025840977],
    [0.0, 542.3421738705956, 242.1099554052592],
    [0.0, 0.0, 1.0]
])

D = np.array([[0.20528603028454656, -0.766640680691422,
               -0.0009661402178902956, 0.0011189160210831846,
               0.9763000357883636]])


# ===================== í”½ì…€ â†’ ë¡œë´‡ ë³€í™˜ =====================
def pixel_to_robot(cx, cy, frame_w, frame_h):
    dx = (cx - frame_w / 2) * SCALE_X
    dy = (cy - frame_h / 2) * SCALE_Y
    robot_x = POSE_HOME[0] + OFFSET_X - dy 
    robot_y = POSE_HOME[1] + OFFSET_Y - dx 
    robot_z = POSE_HOME[2]
    return [robot_x, robot_y, robot_z, POSE_HOME[3], POSE_HOME[4], POSE_HOME[5]]


# ===================== OpenCV ê¸°ë°˜ ê°ë„ ê³„ì‚° =====================
def get_angle_from_roi(frame, x1, y1, x2, y2):
    """ROI ì˜ë¼ì„œ minAreaRect ê¸°ë°˜ ê°ë„ ê³„ì‚°"""
    roi = frame[int(y1):int(y2), int(x1):int(x2)]
    if roi.size == 0:
        return 0.0

    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        return 0.0

    c = max(contours, key=cv2.contourArea)
    rect = cv2.minAreaRect(c)
    ((_, _), (_, _), angle) = rect
    if angle < -45:
        angle = 90 + angle
    return angle


# ===================== YOLO ê°ì§€ =====================
def detect_object(model, frame):
    global accuracy
    results = model.predict(frame, imgsz=640, conf=0.55, verbose=False)
    r = results[0]
    boxes = r.boxes
    frame_vis = frame.copy()

    if len(boxes) == 0:
        return frame_vis, None, None, None, None, None, False

    box = max(boxes, key=lambda b: float(b.conf[0]))
    x1, y1, x2, y2 = box.xyxy[0]
    conf = float(box.conf[0])
    cls = int(box.cls[0])
    name = r.names[cls]
    accuracy = conf

    cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)
    angle = get_angle_from_roi(frame, x1, y1, x2, y2)

    # === ë…¸ë€ì  ê°ì§€ (ë¶ˆëŸ‰í’ˆ) ===
    roi = frame[int(y1):int(y2), int(x1):int(x2)]
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    lower_yellow = np.array([20, 100, 150])
    upper_yellow = np.array([35, 255, 255])
    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)
    yellow_ratio = np.sum(mask_yellow > 0) / (roi.shape[0] * roi.shape[1])

    is_defect = yellow_ratio > 0.002
    status_text = "DEFECT" if is_defect else "OK"
    color_box = (0, 0, 255) if is_defect else (0, 255, 0)

    cv2.rectangle(frame_vis, (int(x1), int(y1)), (int(x2), int(y2)), color_box, 2)
    cv2.circle(frame_vis, (cx, cy), 5, (0, 255, 255), -1)
    cv2.putText(frame_vis,
                f"{name} ({conf:.2f}) | {angle:.1f}Â° | {status_text}",
                (int(x1), int(y1) - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_box, 2)

    print(f"ğŸ§© ê°ì§€ë¨: {name} | conf={conf:.2f} | angle={angle:.1f}Â° | defect={is_defect} | yellow_ratio={yellow_ratio:.4f}")
    return frame_vis, (cx, cy), angle, conf, frame.shape[1], frame.shape[0], is_defect


# ===================== ì¹´ë©”ë¼ ìŠ¤ë ˆë“œ =====================
def camera_thread(stop_event, frame_container):
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ ì¹´ë©”ë¼ ì—´ê¸° ì‹¤íŒ¨")
        return
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    w, h = 640, 480
    new_K, roi = cv2.getOptimalNewCameraMatrix(K, D, (w, h), 1, (w, h))
    mapx, mapy = cv2.initUndistortRectifyMap(K, D, None, new_K, (w, h), 5)

    while not stop_event.is_set():
        ret, frame = cap.read()
        if ret:
            undistorted = cv2.remap(frame, mapx, mapy, cv2.INTER_LINEAR)
            frame_container["frame"] = undistorted
        time.sleep(0.03)
    cap.release()


# ===================== ë©”ì¸ ë£¨í‹´ =====================
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--port", type=str, default="/dev/ttyACM0")
    parser.add_argument("--baud", type=int, default=115200)
    parser.add_argument("--model", type=str, default="best.pt")
    args = parser.parse_args()

    model = YOLO(args.model)
    print("âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    mc = CobotClass(args.port, args.baud)
    mc.power_on()
    time.sleep(1)
    mc.send_angles([0,0,0,0,0,0],20)
    time.sleep(4)
    mc.send_coords(POSE_CLEAR, DEFAULT_SPEED, 0)
    time.sleep(2)
    mc.send_coords(POSE_HOME, DEFAULT_SPEED, 0)
    mc.set_gripper_mode(0)
    mc.set_electric_gripper(0)
    mc.set_gripper_value(50, 20, 1)
    print("ğŸ  í™ˆ í¬ì¦ˆ ë„ë‹¬ ë° ì´ˆê¸°í™” ì™„ë£Œ")

    frame_container, stop_event = {"frame": None}, threading.Event()
    cam_thread = threading.Thread(target=camera_thread, args=(stop_event, frame_container), daemon=True)
    cam_thread.start()

    print("ğŸ“· ê°ì§€ ì¤‘ (3ì´ˆ ì´ìƒ ìœ ì§€ ì‹œ í”½ì—… ì‹œì‘)")
    detect_start, detected, detected_angle = None, None, None

    while not stop_event.is_set():
        frame = frame_container.get("frame")
        if frame is None:
            continue
        frame_vis, result, angle, conf, fw, fh, is_defect = detect_object(model, frame)

        if result:
            cx, cy = result
            if detect_start is None:
                detect_start = time.time()
            elif time.time() - detect_start > 3.0:
                print(f"ğŸŸ¢ ë¬¼ì²´ í™•ì •: (cx={cx:.1f}, cy={cy:.1f}), angle={angle:.1f}Â°")
                detected = pixel_to_robot(cx, cy, fw, fh)
                detected_angle = angle
                stop_event.set()
                break
        else:
            detect_start = None

        cv2.imshow("Camera", frame_vis)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            stop_event.set()
            break

    cam_thread.join()
    cv2.destroyAllWindows()

    if not detected:
        print("âŒ ê°ì§€ ì‹¤íŒ¨ ë˜ëŠ” ì¤‘ë‹¨ë¨")
        return

    x, y, z, r, p, yaw = detected
    print(f"ğŸ¯ ì´ë™ ëª©í‘œ ì¢Œí‘œ: {detected}")

    # === 1ï¸âƒ£ ì¢Œí‘œ ì´ë™ (Z+70 ì§€ì )
    mc.send_coords([x-5, y, 325, r, p, yaw], 25, 1)
    time.sleep(1.5)

    # === 2ï¸âƒ£ í”½ì—… ì§ì „ ê°ë„ ì¬ê²€ì¶œ ë° ë³´ì • ===
    frame = frame_container.get("frame")
    if frame is not None:
        re_frame, _, new_angle, _, _, _, _ = detect_object(model, frame)
        if new_angle is not None:
            print(f"ğŸ“ í”½ì—… ì§ì „ ê°ë„ ì¬ì¸¡ì •: {new_angle:.1f}Â°")
            angles = mc.get_angles()
            if angles:
                angles[5] += new_angle
                mc.send_angles(angles, 25)
                time.sleep(2)
                print(f"ğŸ§­ ê·¸ë¦¬í¼ íšŒì „ ë³´ì • ì™„ë£Œ ({new_angle:.1f}Â°)")

    # === 3ï¸âƒ£ ì ì§„ì  í•˜ê°• ===
    for step in [30, 20]:
        down = mc.get_coords()
        if down:
            down[0], down[1] = x, y
            down[2] -= step
            mc.send_coords(down, 20, 0)
            time.sleep(2.5)
            print("ğŸ“‰ í•˜ê°• ì¤‘:", mc.get_coords())

    # === 4ï¸âƒ£ ì§‘ê¸° ===
    mc.set_gripper_value(10, 30, 1)
    time.sleep(1.5)

    # === 5ï¸âƒ£ ìƒìŠ¹ ===
    up = mc.get_coords()
    up[2] += 100
    mc.send_coords(up, 25, 0)
    time.sleep(1.5)

    # === 6ï¸âƒ£ ë¶„ë¥˜ ì´ë™ ===
    mc.send_coords(POSE_CLEAR, DEFAULT_SPEED, 0)
    time.sleep(1)

    if is_defect:
        print("ğŸ”´ ë¶ˆëŸ‰í’ˆ (ë…¸ë€ ì  ê°ì§€ë¨)")
        mc.send_coords(POSE_PLACE2, DEFAULT_SPEED, 0)
    else:
        print("ğŸŸ¢ ì–‘í’ˆ (ì •ìƒ)")
        mc.send_coords(POSE_PLACE1, DEFAULT_SPEED, 0)

    time.sleep(2)
    mc.set_gripper_value(50, 20, 1)
    mc.send_coords(POSE_CLEAR, DEFAULT_SPEED, 0)
    time.sleep(1)
    mc.send_coords(POSE_HOME, DEFAULT_SPEED, 0)
    print("ğŸ í”½ì—… ë° ë¶„ë¥˜ ì™„ë£Œ â†’ í™ˆ ë³µê·€")


if __name__ == "__main__":
    main()
