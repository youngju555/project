# -*- coding: utf-8 -*-
"""
MyCobot 320 M5 (pymycobot)
[YOLOv8-Seg + ì¹´ë©”ë¼ë³´ì • + ìŠ¤ë ˆë“œ + ìë™ì¢…ë£Œ + ì¢Œí‘œ/ê°ë„ì €ì¥ v9.0]

ğŸ“Œ ì „ì²´ ìˆœì„œ
-------------------------------------------------
1ï¸âƒ£ ì¹´ë©”ë¼ ìŠ¤ë ˆë“œ: í”„ë ˆì„ ì†¡ì¶œë§Œ ìˆ˜í–‰
2ï¸âƒ£ ë©”ì¸ ë£¨í”„: ROI ë‚´ YOLO-Seg ê°ì§€ â†’ 3ì´ˆ ìœ ì§€ ì‹œ
3ï¸âƒ£ ì¢Œí‘œ ê³„ì‚°(pixel_to_robot) + ê°ë„ ì €ì¥
4ï¸âƒ£ ì¹´ë©”ë¼ ì¢…ë£Œ â†’ ë¡œë´‡ ì´ë™ (Homeâ†’Pick(ê°ë„ë³´ì •)â†’Placeâ†’Home)
"""

import threading
import cv2
import time
import argparse
import numpy as np
import json
import os
from ultralytics import YOLO

# ======================================================
# 0ï¸âƒ£ ë¡œë´‡ í´ë˜ìŠ¤ ë¡œë“œ
# ======================================================
try:
    from pymycobot.mycobot320 import MyCobot320 as CobotClass
except Exception:
    from pymycobot.mycobot import MyCobot as CobotClass


# ======================================================
# 1ï¸âƒ£ í¬ì¦ˆ ì •ì˜
# ======================================================
POSES = {
    "Home":  [59.8, -215.9, 354.6, -175.33, 8.65, 86.68],
    "Clear": [264.0, -1.0, 379.0, -153, 11, -106],
    "Place": [333.0, 11.0, 170.0, -175, -0.08, -89.0],
}
DEFAULT_SPEED = 20



# ======================================================
# 2ï¸âƒ£ ì¹´ë©”ë¼ ë³´ì •ê°’ ë¡œë“œ
# ======================================================
def load_camera_params(yaml_path="/home/vboxuser/robotarm/camera_info.yaml"):
    # ìœˆë„ìš° ê²½ë¡œ ì˜ˆì‹œ: r"C:\Users\peo00\camera_info.yaml"
    fs = cv2.FileStorage(yaml_path, cv2.FILE_STORAGE_READ)
    if not fs.isOpened():
        raise FileNotFoundError(f"âŒ '{yaml_path}' íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    camera_matrix = fs.getNode("camera_matrix").mat()
    dist_coeffs = fs.getNode("distortion_coefficients").mat()
    fs.release()
    print("ğŸ“· ì¹´ë©”ë¼ ë³´ì • íŒŒë¼ë¯¸í„° ë¡œë“œ ì™„ë£Œ")
    return camera_matrix, dist_coeffs


# ======================================================
# 3ï¸âƒ£ í”½ì…€ â†’ ë¡œë´‡ ì¢Œí‘œ ë³€í™˜ (ì˜¤í”„ì…‹ í¬í•¨)
# ======================================================
def pixel_to_robot(cx, cy, distance_cm, camera_matrix, dist_coeffs):
    pts = np.array([[[cx, cy]]], dtype=np.float32)
    undistorted = cv2.undistortPoints(pts, camera_matrix, dist_coeffs, P=None)
    norm_x, norm_y = undistorted[0, 0]

    # ê¹Šì´ ê³„ì‚° (cm â†’ mm)
    scale_z = distance_cm * 10.0
    x_cam = norm_x * scale_z
    y_cam = norm_y * scale_z

    # ----------------------------------------
    # ğŸ“ ì˜¤í”„ì…‹ (í…ŒìŠ¤íŠ¸ ê¸°ì¤€)
    # ----------------------------------------
    TCP_BASE_OFFSET_X = 59.8
    TCP_BASE_OFFSET_Y = -215.9
    TCP_BASE_OFFSET_Z = 354.6
    CAMERA_TO_TCP_OFFSET_X = 75   # â† ì¹´ë©”ë¼ê°€ Xë°©í–¥ìœ¼ë¡œ 90mm ì•ì— ìˆìŒ
    CAMERA_TO_TCP_OFFSET_Y = 0.0
    CAMERA_TO_TCP_OFFSET_Z = 170.0  # â† ì‹¤ì œ ë†’ì´ ì°¨ì´ (í˜„ì¬ëŠ” ì‚¬ìš© ì•ˆ í•¨)

    # ----------------------------------------
    # ë¡œë´‡ ì¢Œí‘œ ê³„ì‚°
    # ----------------------------------------
    robot_x = TCP_BASE_OFFSET_X + CAMERA_TO_TCP_OFFSET_X + y_cam
    robot_y = TCP_BASE_OFFSET_Y + CAMERA_TO_TCP_OFFSET_Y + x_cam

    # ZëŠ” í˜„ì¬ í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ê³ ì • (ì›€ì§ì´ì§€ ì•ŠìŒ)
    robot_z = TCP_BASE_OFFSET_Z   # scale_z ì ìš© ì•ˆ í•¨

    return {"x": round(robot_x, 2), "y": round(robot_y, 2), "z": round(robot_z, 2)}



# ======================================================
# 4ï¸âƒ£ YOLO ê°ì§€ í•¨ìˆ˜ (Segmentation ê¸°ë°˜)
# ======================================================
def detect_yolo(model, frame):
    """
    YOLOv8 Segmentation ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°ì²´ë¥¼ ê°ì§€í•˜ê³ ,
    ë§ˆìŠ¤í¬ë¡œë¶€í„° íšŒì „ ê°ë„(minAreaRect)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    # stream=True ëŒ€ì‹  predict ì‚¬ìš©, device=0 (GPU) ì„¤ì •
    results = model.predict(frame, imgsz=640, conf=0.6, verbose=False, device='cpu')
    
    frame_vis = frame.copy()
    detected_info = []
    FIXED_DISTANCE_CM = 30.0 # ê³ ì • ê¹Šì´ ê°’ (í•„ìš”ì‹œ ìˆ˜ì •)

    # ê²°ê³¼ê°€ ìˆê³ , ë§ˆìŠ¤í¬ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
    if len(results) > 0 and results[0].masks is not None:
        masks = results[0].masks
        confs = results[0].boxes.conf.cpu().numpy()

        # ê°ì§€ëœ ëª¨ë“  ë§ˆìŠ¤í¬ì— ëŒ€í•´ ë°˜ë³µ
        for i, mask in enumerate(masks.data):
            conf = confs[i]
            
            # ë§ˆìŠ¤í¬ ë°ì´í„°ë¥¼ (H, W) í˜•íƒœë¡œ ë³€í™˜
            mask_np = (mask.cpu().numpy() * 255).astype(np.uint8)
            
            # ì›ë³¸ í”„ë ˆì„ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            mask_np = cv2.resize(mask_np, (frame_vis.shape[1], frame_vis.shape[0]))

            # ğŸ”¹ ë§ˆìŠ¤í¬ì—ì„œ ì™¸ê³½ì„ (Contour) ì¶”ì¶œ
            contours, _ = cv2.findContours(mask_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if len(contours) == 0:
                continue

            # ğŸ”¹ ê°€ì¥ í° ì»¨íˆ¬ì–´ ì„ íƒ
            cnt = max(contours, key=cv2.contourArea)
            
            # ğŸ”¹ ìµœì†Œ ì˜ì—­ ì‚¬ê°í˜•(íšŒì „ëœ ì‚¬ê°í˜•) ê³„ì‚°
            rect = cv2.minAreaRect(cnt)
            (cx, cy), (w, h), angle = rect

            # ğŸ”¹ íšŒì „ ë°•ìŠ¤ ì‹œê°í™”
            box = cv2.boxPoints(rect)
            box = np.int0(box)
            cv2.drawContours(frame_vis, [box], 0, (255, 255, 0), 2) # ì²­ë¡ìƒ‰

            # ğŸ”¹ ê°ë„ í‘œì‹œ
            cv2.putText(frame_vis, f"Angle: {angle:.1f}", (int(cx), int(cy)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

            # ğŸ”¹ ì–‘í’ˆ / ë¶ˆëŸ‰í’ˆ íŒë‹¨ (ì‹ ë¢°ë„ ê¸°ì¤€)
            if conf >= 0.9:
                label = f"ì–‘í’ˆ ({conf:.2f})"
                color = (0, 255, 0) # ì´ˆë¡ìƒ‰
            else:
                label = f"ë¶ˆëŸ‰í’ˆ ({conf:.2f})"
                color = (0, 0, 255) # ë¹¨ê°„ìƒ‰

            cv2.putText(frame_vis, label, (int(cx - 50), int(cy - 40)),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

            # ğŸ”¹ ë°˜í™˜í•  ì •ë³´ ì¶”ê°€ (cx, cy, ê³ ì •ê±°ë¦¬, ê°ë„)
            # ë©”ì¸ ë£¨í”„ëŠ” ì²« ë²ˆì§¸ ê°ì²´ë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ, ëª¨ë‘ ì¶”ê°€
            detected_info.append(("object", (int(cx), int(cy)), FIXED_DISTANCE_CM, angle))

    # ì‹œê°í™”ëœ í”„ë ˆì„ê³¼ ê°ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    return frame_vis, detected_info


# ======================================================
# 5ï¸âƒ£ ì¹´ë©”ë¼ ìŠ¤ë ˆë“œ (í”„ë ˆì„ ì†¡ì¶œë§Œ)
# ======================================================
def camera_capture_thread(stop_event, frame_container):
    # â­ï¸ ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì¹´ë©”ë¼ ID 1ë²ˆìœ¼ë¡œ ë³€ê²½
    cap = cv2.VideoCapture(0) 
    if not cap.isOpened():
        print("âš ï¸ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ID: 1)")
        return
    
    # â­ï¸ ì¹´ë©”ë¼ í•´ìƒë„ ì„¤ì • (ì‚¬ìš©ì ì˜ˆì œ ì½”ë“œ ê¸°ì¤€)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

    print("ğŸ“· ì¹´ë©”ë¼ ìŠ¤ë ˆë“œ ì‹œì‘ (í”„ë ˆì„ ì†¡ì¶œ ì¤‘...)")
    while not stop_event.is_set():
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.01)
            continue
        frame_container["frame"] = frame
    cap.release()
    print("ğŸ“· ì¹´ë©”ë¼ ìŠ¤ë ˆë“œ ì¢…ë£Œ")


# ======================================================
# 6ï¸âƒ£ ë¡œë´‡ ì´ë™ í—¬í¼
# ======================================================
def move_to(mc, name, speed=DEFAULT_SPEED):
    if name not in POSES:
        print(f"âš ï¸ Unknown pose: {name}")
        return
    target = POSES[name]
    mc.send_coords(target, speed, 0)
    time.sleep(2)
    print(f"âœ… Move â†’ {name}")


# ======================================================
# 7ï¸âƒ£ ì¢Œí‘œ JSON ì €ì¥
# ======================================================
def save_pick_coordinate(coord, angle, filename="picking_target.json"):
    data_to_save = {
        "coordinates": coord,
        "angle": round(angle, 2)
    }
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data_to_save, f, indent=4, ensure_ascii=False)
    print(f"ğŸ’¾ ì¢Œí‘œ/ê°ë„ ì €ì¥ ì™„ë£Œ â†’ {filename} : {data_to_save}")


# ======================================================
# 8ï¸âƒ£ ë©”ì¸ ë£¨í”„
# ======================================================
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--port", type=str, default="/dev/ttyACM0")
    parser.add_argument("--baud", type=int, default=115200)
    parser.add_argument("--speed", type=int, default=20)
    # â­ï¸ ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ Seg ëª¨ë¸ ê²½ë¡œë¡œ ê¸°ë³¸ê°’ ë³€ê²½
    parser.add_argument("--model", type=str, 
                        default="/home/young/Downloads/best.pt")
    parser.add_argument("--dry-run", action="store_true")
    args = parser.parse_args()

    detected_angle = None # ìµœì¢… í™•ì •ëœ ê°ë„ë¥¼ ì €ì¥í•  ë³€ìˆ˜

    # YOLO ëª¨ë¸ ë¡œë“œ
    print(f"ğŸ§  YOLO ëª¨ë¸ ë¡œë“œ ì¤‘: {args.model}")
    model = YOLO(args.model)
    model.to("cpu")
    print("âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # ì¹´ë©”ë¼ ë³´ì •ê°’ ë¡œë“œ (ê²½ë¡œ í™•ì¸ í•„ìˆ˜)
    try:
        camera_matrix, dist_coeffs = load_camera_params(r"/home/young/Downloads/camera_info.yaml") # ìœˆë„ìš° ê²½ë¡œ ì˜ˆì‹œ
    except FileNotFoundError as e:
        print(e)
        print("ğŸ”´ camera_info.yaml ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # ë¡œë´‡ ì—°ê²°
    mc = None
    if not args.dry_run:
        try:
            mc = CobotClass(args.port, args.baud)
            time.sleep(0.5)
            mc.power_on()
            print("ğŸ”Œ Power ON ì™„ë£Œ")
            move_to(mc, "Home", args.speed)
            mc.set_gripper_mode(0)
            mc.set_electric_gripper(0)
            mc.set_gripper_value(0, 20, 1)  # ì—´ë¦¼
        except Exception as e:
            print(f"ğŸ”´ ë¡œë´‡ ì—°ê²° ì‹¤íŒ¨: {e}")
            print("ğŸ”´ í¬íŠ¸({args.port})ë¥¼ í™•ì¸í•˜ê±°ë‚˜ --dry-run ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            return
    else:
        print("ğŸŸ¡ dry-run ëª¨ë“œ (ë¡œë´‡ ë¯¸ì—°ê²°)")

    # ì¹´ë©”ë¼ ìŠ¤ë ˆë“œ ì‹œì‘
    frame_container = {"frame": None}
    stop_event = threading.Event()
    cam_thread = threading.Thread(
        target=camera_capture_thread, args=(stop_event, frame_container), daemon=True
    )
    cam_thread.start()

    print("âœ… ë©”ì¸ ë£¨í”„ ì‹œì‘ (ROI ê°ì§€ í›„ 3ì´ˆ ìœ ì§€ ì‹œ ì‹¤í–‰)")
    roi_detect_start = None
    DETECT_HOLD_TIME = 3.0
    detected_coord = None

    try:
        while not stop_event.is_set():
            frame = frame_container.get("frame")
            if frame is None:
                time.sleep(0.01) # ì¹´ë©”ë¼ê°€ ì¼œì§€ëŠ” ì¤‘
                continue

            # ROI í‘œì‹œ
            h, w, _ = frame.shape
            roi_x1, roi_y1 = int(w * 0.3), int(h * 0.3)
            roi_x2, roi_y2 = int(w * 0.7), int(h * 0.7)
            cv2.rectangle(frame, (roi_x1, roi_y1), (roi_x2, roi_y2), (0, 255, 0), 2)
            cv2.drawMarker(frame, (w // 2, h // 2), (0, 255, 0), cv2.MARKER_CROSS, 15, 2)

            # â­ï¸ YOLO ê°ì§€ ìˆ˜í–‰ (Segmentation ê¸°ë°˜)
            processed_frame, detected = detect_yolo(model, frame)
            
            in_roi = False
            
            # ê°ì§€ ê²°ê³¼ ìˆì„ ë•Œ (ì²« ë²ˆì§¸ ê°ì²´ë§Œ ì²˜ë¦¬)
            if detected:
                # â­ï¸ detect_yoloê°€ bbox ëŒ€ì‹  angleì„ ë°˜í™˜
                # _, (cx, cy), dist, bbox = detected[0] (ê¸°ì¡´)
                _, (cx, cy), dist, angle_from_yolo = detected[0] # (ë³€ê²½)

                if roi_x1 < cx < roi_x2 and roi_y1 < cy < roi_y2:
                    in_roi = True

                    # -------------------------------
                    # ğŸ”¸ YOLO Segmentation ê¸°ë°˜ ê°ë„ ì‚¬ìš©
                    # -------------------------------
                    # (ê¸°ì¡´ì˜ bbox ê¸°ë°˜ ê°ë„ ì¶”ì • ë¡œì§ ì‚­ì œ)
                    # â­ï¸ detect_yoloì—ì„œ ê³„ì‚°ëœ ê°ë„ë¥¼ ë°”ë¡œ ì‚¬ìš©
                    if angle_from_yolo is not None:
                        detected_angle = angle_from_yolo
                else:
                    # ROI ë°–ì— ìˆìœ¼ë©´ ê°ë„ ì´ˆê¸°í™”
                    detected_angle = None
            else:
                 detected_angle = None


            # ROI ë‚´ë¶€ì— ê°ì§€ëœ ê²½ìš° (3ì´ˆ ìœ ì§€ ì‹œ ì¢Œí‘œ í™•ì •)
            if in_roi:
                if roi_detect_start is None:
                    roi_detect_start = time.time()
                    print("ğŸ”µ ROI ê°ì§€ ì‹œì‘ (3ì´ˆ ìœ ì§€ ì‹œ ì¢Œí‘œ í™•ì •)")
                else:
                    elapsed = time.time() - roi_detect_start
                    cv2.putText(processed_frame, f"ê°ì§€ ì¤‘... {elapsed:.1f}s", (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
                    
                    if elapsed >= DETECT_HOLD_TIME:
                        print("ğŸŸ¢ ê°ì§€ ìœ ì§€ 3ì´ˆ â†’ ì¢Œí‘œ ê³„ì‚° ì‹œì‘")
                        detected_coord = pixel_to_robot(cx, cy, dist, camera_matrix, dist_coeffs)
                        
                        # â­ï¸ ìµœì¢… ì¢Œí‘œì™€ 'ê°ë„'ë¥¼ í•¨ê»˜ ì¶œë ¥
                        print(f"ğŸ¯ ë¬¼ì²´ ì¢Œí‘œ: {detected_coord}, ê°ë„: {detected_angle}") 
                        
                        # (ì£¼ì„ ì²˜ë¦¬ëœ ê·¸ë¦¬í¼/íšŒì „ë³´ì • ë¡œì§ì€ ê·¸ëŒ€ë¡œ ë‘ )
                        
                        # ... (ê¸°ì¡´ ê·¸ë¦¬í¼ ë™ì‘ ì½”ë“œ) ...
                        if not args.dry_run and mc:
                            try:
                                mc.set_gripper_state(0, 80)   # ì™„ì „ ì—´ê¸°
                                mc.set_gripper_state(1, 80)   # ì™„ì „ ì—´ê¸°
                                print("ğŸ¤– ê·¸ë¦¬í¼ ë™ì‘ ì™„ë£Œ")
                            except Exception as e:
                                print(f"âš ï¸ ê·¸ë¦¬í¼ ë™ì‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

                        # -------------------------------
                        # âœ… ê°ì§€ ì™„ë£Œ í›„ ì¹´ë©”ë¼ ì¢…ë£Œ
                        # -------------------------------
                        stop_event.set()
                        print("ğŸ“· ì¹´ë©”ë¼ ì¢…ë£Œ ìš”ì²­...")
                        break # while ë£¨í”„ íƒˆì¶œ
            else:
                # ROI ë°–ìœ¼ë¡œ ë²—ì–´ë‚˜ë©´ íƒ€ì´ë¨¸ ì´ˆê¸°í™”
                roi_detect_start = None


            cv2.imshow("Camera View (YOLOv8-Seg)", processed_frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                stop_event.set()
                break

    finally:
        print("ğŸ”„ ìµœì¢… ì •ë¦¬ ì¤‘...")
        stop_event.set()
        if cam_thread.is_alive():
            cam_thread.join()
        cv2.destroyAllWindows()
        print("âœ… ëª¨ë“  ì°½ ì¢…ë£Œ")

    # ==================================================
    # âœ… ê°ì§€ëœ ì¢Œí‘œê°€ ìˆìœ¼ë©´ ë¡œë´‡ ì´ë™
    # ==================================================
    if detected_coord:
        # â­ï¸ ì¢Œí‘œì™€ ê°ë„ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        save_pick_coordinate(detected_coord, detected_angle if detected_angle is not None else 0.0)

        print("ğŸ¤– ë¡œë´‡ ì´ë™ ì‹œì‘...")
        if not args.dry_run and mc:
            mc.set_gripper_mode(0)
            mc.set_electric_gripper(0)
            
            base_r = -175.33
            base_p = 8.65
            base_y = 86.68 # Home í¬ì¦ˆì˜ 6ì¶•(Yaw) ê°’

            # â­ï¸ ê°ì§€ëœ ê°ë„(detected_angle)ë¥¼ ë¡œë´‡ 6ì¶•(Yaw)ì— ë°˜ì˜
            # (ì£¼ì˜) angle ê°’ì˜ ë²”ìœ„(0~90, 0~-90)ì™€ ë¡œë´‡ íšŒì „ ë°©í–¥(+, -)ì„ í…ŒìŠ¤íŠ¸í•˜ì—¬
            # yaw_offset ë³´ì •ê°’(ì˜ˆ: 0.35)ì„ íŠœë‹í•´ì•¼ í•©ë‹ˆë‹¤.
            # cv2.minAreaRectì˜ ê°ë„ëŠ” ë³µì¡í•˜ë¯€ë¡œ í…ŒìŠ¤íŠ¸ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.
            yaw_offset = (detected_angle if detected_angle is not None else 0.0)
            
            # ì˜ˆ: ê°ë„ê°€ 0~90 ì‚¬ì´ ê°’ë§Œ ë‚˜ì˜¨ë‹¤ë©´, 90ë„(ìˆ˜ì§)ì¼ ë•Œ 0ìœ¼ë¡œ ë³´ì •
            if yaw_offset > 45: # 90ë„ì— ê°€ê¹Œìš¸ìˆ˜ë¡
                 yaw_offset = yaw_offset - 90 
            
            # (ë³´ì • ê³„ìˆ˜ íŠœë‹ í•„ìš”)
            yaw_correction = yaw_offset * 1.0 # ì˜ˆì‹œ: 1.0ìœ¼ë¡œ ì„¤ì •
            
            wrist_yaw = base_y + yaw_correction   # ğŸ“Œ YOLO ê°ë„ ë°˜ì˜
            
            print(f"ğŸ§­ Wrist íšŒì „ ì ìš©: base_y={base_y:.1f}, angle={detected_angle:.1f}, correction={yaw_correction:.1f} â†’ ìµœì¢…={wrist_yaw:.1f}")


            mc.set_gripper_value(50, 20, 1)  # ì—´ë¦¼

            # 1. ìœ„ì—ì„œ ì ‘ê·¼ (Z = 300)
            mc.send_coords(
                [detected_coord["x"], detected_coord["y"], 300.0,
                base_r, base_p, wrist_yaw], # â­ï¸ ê°ë„(wrist_yaw) ì ìš©
                25, 0
            )
            time.sleep(3)

            # 2. ë‚´ë ¤ê°€ì„œ ì§‘ê¸° (Z = 260+40) -> 300? (ê°’ í™•ì¸ í•„ìš”)
            # (Zê°’ì„ ì‹¤ì œ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)
            pick_z = 260.0 + 40.0 # ì˜ˆì‹œ Z
            mc.send_coords(
                [detected_coord["x"], detected_coord["y"], pick_z,
                base_r, base_p, wrist_yaw], # â­ï¸ ê°ë„(wrist_yaw) ì ìš©
                15, 0
            )
            time.sleep(2)

            mc.set_gripper_value(8, 20, 1)  # ë‹«í˜
            time.sleep(1.5)

            # 3. ìœ„ë¡œ ë¹¼ê¸° (Z = 260+100) -> 360?
            mc.send_coords(
                [detected_coord["x"], detected_coord["y"], pick_z + 60.0,
                base_r, base_p, wrist_yaw], # â­ï¸ ê°ë„(wrist_yaw) ì ìš©
                15, 0
            )
            time.sleep(1.5)
            
            # 4. ì´ë™ ë° ë³µê·€
            move_to(mc, "Clear", args.speed)
            move_to(mc, "Place", args.speed)
            mc.set_gripper_state(0, 80) # ê·¸ë¦¬í¼ ì—´ê¸°
            time.sleep(1)
            move_to(mc, "Home", args.speed)
        else:
            print(f"ğŸŸ¢ [dry-run] ì¢Œí‘œ({detected_coord}) ë° ê°ë„({detected_angle:.1f}) ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ")

    if mc:
        mc.power_off()
        print("ğŸ”Œ Power OFF")
    print("ğŸ”’ ì¢…ë£Œ ì™„ë£Œ")


if __name__ == "__main__":
    main()
